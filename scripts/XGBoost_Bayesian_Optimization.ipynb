{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Library Imports\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import imblearn as imbl\n",
    "import xgboost as xgb\n",
    "from hyperopt import hp, tpe, fmin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import plot_roc_curve, roc_curve, auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "##from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#from sklearn_pandas import DataFrameMapper\n",
    "\n",
    "## Custom libraries\n",
    "import index_helpers as ih\n",
    "import data_transformations as dtrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import, index, and split\n",
    "df, cat_feat, num_feat, all_feat = ih.read_and_merge_segmented_data(exlude_expert=False, exclude_meta_data=False)\n",
    "df = ih.index_df_by_person(df)\n",
    "df = dtrans.low_var_exclusion(df, 0.1)\n",
    "\n",
    "### EXTR MODIFICATION ###\n",
    "df = df[df[\"Expert\"]!=2]\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Resp_Condition', 'Gender'])\n",
    "## Removed feature - Symptoms\n",
    "##########################\n",
    "\n",
    "X_train, X_test, y_train, y_test = ih.train_test_split_on_index(features = df.drop(\"Label\", axis=1),\n",
    "                                                                label = df[\"Label\"])\n",
    "\n",
    "#X_train = df.drop(\"Label\", axis=1)\n",
    "#y_train = df[\"Label\"]\n",
    "\n",
    "## Train naive regression model\n",
    "#logit_naive = LogisticRegression(max_iter = 1000).fit(X_train, y_train)\n",
    "#logit_naive.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = X_train.reset_index(drop=False)\n",
    "y_t = y_train.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "RUS = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = RUS.fit_resample(X_t, y_t[\"Label\"])\n",
    "\n",
    "df_res = X_res.merge(y_res, left_index=True, right_index=True)\n",
    "df_res.set_index(['File_Name_split', 'File_n_recording'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_res.drop(columns=['File_Name_split', 'File_n_recording', 'Label'])\n",
    "y = df_res['Label']\n",
    "groups = df_res[\"File_Name_split\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC Naive LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_roc_curve(logit_naive, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify data for GroupKFold\n",
    "#df_reset = df.reset_index()\n",
    "#X = X_train.reset_index(drop=True)\n",
    "#y = y_train.reset_index(drop=True)\n",
    "#groups = y_train.reset_index()['File_Name_split']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_hyperopt = {'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(1)),\n",
    "                  'max_depth': hp.quniform('max_depth', 20, 100, 5),\n",
    "                  'max_delta_step': hp.quniform('max_delta_step', 0, 20, 1),\n",
    "                  'gamma': hp.uniform ('gamma', 1,9),\n",
    "                  'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "                  'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "                  'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "                  'min_child_weight' : hp.quniform('min_child_weight', 0, 20, 1),\n",
    "                  'n_estimators': hp.quniform('n_estimators', 50, 300, 10)}\n",
    "\n",
    "def objective(params):\n",
    "    \n",
    "    ### Casting variables\n",
    "    params = {'learning_rate': float(params['learning_rate']),\n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'max_delta_step': int(params['max_delta_step']),\n",
    "              'gamma': int(params['gamma']),\n",
    "              'reg_alpha': int(params['reg_alpha']),\n",
    "              'reg_lambda': float(params['reg_lambda']),\n",
    "              'colsample_bytree': float(params['colsample_bytree']),\n",
    "              'min_child_weight': int(params['min_child_weight']),\n",
    "              'n_estimators': int(params['n_estimators'])}\n",
    "    \n",
    "    xgb_clf = xgb.XGBClassifier(objective='binary:logistic',**params)\n",
    "    \n",
    "    gkf=GroupKFold(n_splits=5)\n",
    "    best_score = cross_val_score(xgb_clf, X, y, cv=gkf, groups=groups, \n",
    "                                 scoring='roc_auc', n_jobs=-1).mean()\n",
    "    \n",
    "    return -best_score\n",
    "    \n",
    "best_result = fmin(fn=objective, space=param_hyperopt, max_evals=35, algo=tpe.suggest, rstate=np.random.RandomState(42))\n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result_cast = {'learning_rate': float(best_result['learning_rate']),\n",
    "                  'max_depth': int(best_result['max_depth']),\n",
    "                    'max_delta_step': int(best_result['max_delta_step']),\n",
    "                  'gamma': int(best_result['gamma']),\n",
    "                  'reg_alpha': int(best_result['reg_alpha']),\n",
    "                  'reg_lambda': float(best_result['reg_lambda']),\n",
    "                  'colsample_bytree': float(best_result['colsample_bytree']),\n",
    "                  'min_child_weight': int(best_result['min_child_weight']),\n",
    "                  'n_estimators': int(best_result['n_estimators'])}\n",
    "\n",
    "## lets test\n",
    "best_clf = xgb.XGBClassifier(objective='binary:logistic', **best_result_cast)\n",
    "\n",
    "best_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v = X_test.reset_index(drop=True)\n",
    "y_v = y_test.reset_index(drop=True)\n",
    "\n",
    "preds = best_clf.predict_proba(X_v)\n",
    "\n",
    "plot_roc_curve(best_clf, X_v, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost performance\n",
    "\n",
    "Removing one expert at a time:\n",
    "- Expert 3: AUC=0.72\n",
    "- Expert 2: AUC=0.77\n",
    "- Expert 1: AUC=0.73\n",
    "\n",
    "Using ONLY ONE expert at a time:\n",
    "- Expert 1: 0.57\n",
    "- Expert 2: identical to random guess\n",
    "- Expert 3: 0.53..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST FROM LARAS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH_test = Path('../data/features_test_fine_segmentation.csv')\n",
    "\n",
    "X_attempt = pd.read_csv(PATH_test, header=None)\n",
    "X_attempt.columns = all_feat\n",
    "#X_attempt = pd.get_dummies(X_attempt, columns=['Resp_Condition', 'Gender'])\n",
    "X_attempt = X_attempt[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = best_clf.predict_proba(X_attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('features_test_fine_segmentation_predictions.csv', 'w') as f:\n",
    "    for d in preds[:,1]:\n",
    "        f.write(str(d))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
