{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "SVM_Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVPUrEqDpNsC",
        "outputId": "b205c0e9-6320-4ba5-82ac-3ea1a77cb164"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/ML_Project2/ML_Project2/scripts/"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/MyDrive/ML_Project2/ML_Project2/scripts/'\n",
            "/content/drive/MyDrive/ML_Project2/ML_Project2/scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfi7I_PepMI1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, GroupKFold\n",
        "\n",
        "## Custom libraries\n",
        "import index_helpers as ih"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxYrpTFKpMI3"
      },
      "source": [
        "### Import and prep data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofGc4Xd4pMI3"
      },
      "source": [
        "## Import, index, and split\n",
        "\n",
        "segmentation = True\n",
        "fine_segmentation = True\n",
        "\n",
        "# TAKE CARE: change of parameters for read and merge:\n",
        "df = ih.read_and_merge_data(segmentation, fine_segmentation, exclude_expert=False)\n",
        "df = ih.index_df_by_person(df)\n",
        "df = ih.categorical_float_to_int(df)\n",
        "df = ih.categorical_to_dummy(df)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Lk-ttwC1Tt5"
      },
      "source": [
        "#df1, df2, df3 = ih.separate_expert(df)\n",
        "#df[df['Expert']==3.0]\n",
        "#df1 = df[df['Expert']==1.0]\n",
        "#df1.head()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYu3cZu_1PgI"
      },
      "source": [
        "X_train, X_val, y_train, y_val = ih.train_test_split_on_index(features = df.drop(\"Label\", axis=1),\n",
        "                                                             label = df[\"Label\"])\n",
        "\n",
        "## Modify data for GroupKFold\n",
        "groups = y_train.reset_index()['File_Name_split']\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJvrSFJDpMI3"
      },
      "source": [
        "### Create pipeline and fit classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0woYZ82LpMI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7be356cb-bd2f-4afd-928f-140c77121b82"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "## Make pipeline - name classifier \"clf\"\n",
        "clf_pipeline = Pipeline([(\"st_scaler\", StandardScaler()),\n",
        "                        (\"clf\", SVC())])\n",
        "\n",
        "## Use \"clf__\" in order to correctly assign parameters to the clf object\n",
        "clf_param_grid = {'clf__C': [0.1, 1, 10, 100, 1000],\n",
        "                  'clf__tol': [0.0001], # bc it's not really useful to tune that param ?d\n",
        "                  'clf__gamma': [0.1, 1, 10, 100],\n",
        "                  'clf__degree':[0, 1, 2, 3, 4, 5, 6]}\n",
        "## Instantiate GroupKFold to avoid data leakage - to be passed to cv\n",
        "gkf=GroupKFold(n_splits=2)\n",
        "\n",
        "## Set up Randomized search CV --> modulate n_iter for \"quicker\" results\n",
        "clf_rand_auc = RandomizedSearchCV(estimator=clf_pipeline,\n",
        "                                  param_distributions=clf_param_grid,\n",
        "                                  cv=gkf, scoring='roc_auc', verbose=1, n_jobs=2, n_iter=50)\n",
        "\n",
        "## Perform Group K-Cross-validation\n",
        "clf_rand_auc.fit(X_train, y_train, groups=groups)\n",
        "\n",
        "## Print results\n",
        "print(\"Best score: \",  clf_rand_auc.best_score_)\n",
        "print(\"Best estimator: \", clf_rand_auc.best_estimator_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  8.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score:  0.5411889420261413\n",
            "Best estimator:  Pipeline(memory=None,\n",
            "         steps=[('st_scaler',\n",
            "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
            "                ('clf',\n",
            "                 SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None,\n",
            "                     coef0=0.0, decision_function_shape='ovr', degree=6,\n",
            "                     gamma=0.1, kernel='rbf', max_iter=-1, probability=False,\n",
            "                     random_state=None, shrinking=True, tol=0.0001,\n",
            "                     verbose=False))],\n",
            "         verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33poA8Y97VYW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}