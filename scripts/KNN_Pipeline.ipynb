{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "KNN_Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVPUrEqDpNsC",
        "outputId": "21354ead-1cff-48f2-b140-9491f1068e97"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/ML_Project2/ML_Project2/scripts/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ML_Project2/ML_Project2/scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfi7I_PepMI1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV, GroupKFold\n",
        "\n",
        "## Custom libraries\n",
        "import index_helpers as ih"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxYrpTFKpMI3"
      },
      "source": [
        "### Import and prep data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofGc4Xd4pMI3"
      },
      "source": [
        "## Import, index, and split\n",
        "\n",
        "segmentation = True\n",
        "fine_segmentation = True\n",
        "\n",
        "# TAKE CARE: change of parameters for read and merge:\n",
        "df = ih.read_and_merge_data(segmentation, fine_segmentation)\n",
        "df = ih.index_df_by_person(df)\n",
        "df = ih.categorical_float_to_int(df)\n",
        "df = ih.categorical_to_dummy(df)\n",
        "X_train, X_val, y_train, y_val = ih.train_test_split_on_index(features = df.drop(\"Label\", axis=1),\n",
        "                                                             label = df[\"Label\"])\n",
        "\n",
        "## Modify data for GroupKFold\n",
        "groups = y_train.reset_index()['File_Name_split']\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJvrSFJDpMI3"
      },
      "source": [
        "### Create pipeline and fit classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0woYZ82LpMI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e957f9cb-16ed-4671-9df5-198fbda9e4a0"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "## Make pipeline - name classifier \"clf\"\n",
        "clf_pipeline = Pipeline([(\"st_scaler\", StandardScaler()),\n",
        "                        (\"clf\", KNeighborsClassifier())])\n",
        "\n",
        "## Use \"clf__\" in order to correctly assign parameters to the clf object\n",
        "clf_param_grid = {'clf__n_neighbors': list(range(1,30)),\n",
        "                  'clf__leaf_size': list(range(1,50)),\n",
        "                  'clf__p': [1, 2]}\n",
        "\n",
        "## Instantiate GroupKFold to avoid data leakage - to be passed to cv\n",
        "gkf=GroupKFold(n_splits=10)\n",
        "\n",
        "## Set up Randomized search CV\n",
        "clf_rand_auc = RandomizedSearchCV(estimator=clf_pipeline,\n",
        "                                  param_distributions=clf_param_grid,\n",
        "                                  cv=gkf, scoring='roc_auc', verbose=1, n_jobs=2, n_iter=50)\n",
        "\n",
        "## Perform Group K-Cross-validation\n",
        "clf_rand_auc.fit(X_train, y_train, groups=groups)\n",
        "\n",
        "## Print results\n",
        "print(\"Best score: \",  clf_rand_auc.best_score_)\n",
        "print(\"Best estimator: \", clf_rand_auc.best_estimator_)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=2)]: Done 500 out of 500 | elapsed: 16.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best score:  0.5422848963156615\n",
            "Best estimator:  Pipeline(memory=None,\n",
            "         steps=[('st_scaler',\n",
            "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
            "                ('clf',\n",
            "                 KNeighborsClassifier(algorithm='auto', leaf_size=25,\n",
            "                                      metric='minkowski', metric_params=None,\n",
            "                                      n_jobs=None, n_neighbors=24, p=2,\n",
            "                                      weights='uniform'))],\n",
            "         verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}